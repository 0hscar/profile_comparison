print("ai_utils.py loaded")
import os
from dotenv import load_dotenv
from comparator.utils.timing_utils import timeit
from django.http import JsonResponse
import json
import openai
import re


# Load .env file from the backend directory
def compare_profiles(user_profile, competitor_profiles):
    """
    Dynamically calculate averages for all numeric fields present in competitor profiles.
    Returns a comparison dictionary.
    """
    if not competitor_profiles:
        return {}

    # Collect all keys from all competitor profiles
    all_keys = set()
    for p in competitor_profiles:
        all_keys.update(p.keys())

    # Only average numeric fields
    averages = {}
    for key in all_keys:
        values = [p[key] for p in competitor_profiles if key in p and isinstance(p[key], (int, float))]
        if values:
            averages[key] = sum(values) / len(values)

    # For boolean fields, show if any competitor has it True
    bool_fields = [k for k in all_keys if any(isinstance(p.get(k), bool) for p in competitor_profiles)]
    competitor_field_presence = {field: any(p.get(field, False) for p in competitor_profiles) for field in bool_fields}

    comparison = {
        "user": user_profile,
        "competitors": competitor_profiles,
        "averages": averages,
        "competitor_field_presence": competitor_field_presence,
    }
    return comparison

def mock_suggestion(business_profile, competitors_profiles):
    """
    Given a business profile and a list of competitor profiles,
    return a summary and actionable suggestions as if generated by an LLM.
    This is the mock implementation and is used as a fallback if no LLM is available.
    """
    # Extract some basic stats for demonstration
    user_reviews = business_profile.get("review_count", 0)
    user_rating = business_profile.get("average_rating", 0)
    user_photos = business_profile.get("photo_count", 0)
    user_fields = business_profile.get("fields_present", [])

    avg_reviews = int(sum(c.get("review_count", 0) for c in competitors_profiles) / max(len(competitors_profiles), 1))
    avg_rating = round(sum(c.get("average_rating", 0) for c in competitors_profiles) / max(len(competitors_profiles), 1), 2)
    avg_photos = int(sum(c.get("photo_count", 0) for c in competitors_profiles) / max(len(competitors_profiles), 1))

    # Determine missing fields
    critical_fields = {"hours", "description", "menu_link", "address", "phone"}
    missing_fields = critical_fields - set(user_fields)

    # Compose a mock "AI" response
    summary = (
        f"Your business has {user_reviews} reviews (avg rating: {user_rating}). "
        f"Competitors average {avg_reviews} reviews (avg rating: {avg_rating}).\n"
        f"You have {user_photos} photos; competitors average {avg_photos}."
    )

    suggestions = []
    if user_photos < avg_photos:
        suggestions.append(f"Add more photos. Competitors average {avg_photos}, you have {user_photos}.")
    if user_reviews < avg_reviews:
        suggestions.append(f"Encourage more reviews. Competitors average {avg_reviews}, you have {user_reviews}.")
    if missing_fields:
        suggestions.append(f"You're missing these important fields: {', '.join(missing_fields)}.")
    if user_rating < avg_rating:
        suggestions.append("Consider ways to improve your average rating, such as responding to reviews or improving service.")

    # Mock: If no suggestions, say you're doing great!
    if not suggestions:
        suggestions.append("Your profile is as complete or better than your competitors. Great job!")

    return {
        "summary": summary,
        "suggestions": suggestions
    }

def generate_comparison_suggestions(comparison, competitors_profiles):
    """
    Use OpenAI to generate a summary and concrete suggestions.
    Returns a dict with the summary/suggestions and a visible note about which AI was used.
    """
    openai_api_key = os.environ.get("OPENAI_API_KEY")
    print("OpenAI API Key:", openai_api_key)
    if not openai_api_key:
        # fallback to mock if no key
        result = mock_suggestion(comparison, competitors_profiles)
        result["ai_provider"] = "mock"
        result["ai_note"] = "Using mock AI (not OpenAI)."
        return result
    client = openai.OpenAI(api_key=openai_api_key)
    prompt = (
        "Given the following business profile comparison, generate a summary and concrete suggestions for improvement. "
        "Be specific and actionable. Here is the data:\n\n"
        f"{json.dumps(comparison, indent=2)}"
    )
    try:
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "You are a helpful business profile consultant."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=350,
            temperature=0.7,
        )
        content = response.choices[0].message.content
        return {
            "ai_summary": content,
            "ai_provider": "openai",
            "ai_note": "Using OpenAI for summary and suggestions."
        }
    except Exception as e:
        return {
            "ai_summary": f"AI suggestion unavailable: {str(e)}",
            "ai_provider": "error",
            "ai_note": "OpenAI call failed, see ai_summary for error."
        }


def extract_json_from_response(content):
    """
    Extract JSON from a string, handling markdown code blocks if present.
    """
    # Try to extract JSON from markdown code block if present
    match = re.search(r'```(?:json)?\s*([\s\S]+?)\s*```', content)
    if match:
        json_str = match.group(1)
    else:
        json_str = content

    # Strip whitespace and try to parse
    json_str = json_str.strip()
    # print("Parsing this JSON string:", repr(json_str))
    return json.loads(json_str)

@timeit("OpenAI API call")
def sendToAI(prompt):
    # Universal function to send a prompt to OpenAI and return the response.
    ai_api_key = os.environ.get("OPENAI_API_KEY")
    if not ai_api_key:
        return JsonResponse({
            "error": "OpenAI API key not configured."
        }, status=500)
    try:
        client = openai.OpenAI(api_key=ai_api_key)
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "You are a business profile consultant."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=5000,
            temperature=0.7,
        )
        content = response.choices[0].message.content
        print("Total tokens: ", response.usage.total_tokens)
        # Check if the response is valid JSON
        try:
            result = extract_json_from_response(content)

            return JsonResponse(result, status=200)
        except Exception as e:
            print("Exception in sendToAI", e)
            return JsonResponse({
                "error": "OpenAI did not return valid JSON / TOKEN LIMIT REACHED",
                "raw_response": content,
                "exception": str(e)
            }, status=500)
        return JsonResponse(result)

    except Exception as e:
        return JsonResponse({
            "error": f"OpenAI API call failed: {str(e)}"
        }, status=500)
