print("ai_utils.py loaded")
import os
from pydantic import BaseModel
from dotenv import load_dotenv
from comparator.utils.ai_prompts import restuaruant_compare_prompt_system, restaurant_compare_prompt_user
from comparator.utils.timing_utils import timeit
from django.http import JsonResponse
import json
import openai
import re
from typing import Any


def mock_suggestion(business_profile, competitors_profiles):
    """
    Given a business profile and a list of competitor profiles,
    return a summary and actionable suggestions as if generated by an LLM.
    This is the mock implementation and is used as a fallback if no LLM is available.
    """
    # Extract some basic stats for demonstration
    user_reviews = business_profile.get("review_count", 0)
    user_rating = business_profile.get("average_rating", 0)
    user_photos = business_profile.get("photo_count", 0)
    user_fields = business_profile.get("fields_present", [])

    avg_reviews = int(sum(c.get("review_count", 0) for c in competitors_profiles) / max(len(competitors_profiles), 1))
    avg_rating = round(sum(c.get("average_rating", 0) for c in competitors_profiles) / max(len(competitors_profiles), 1), 2)
    avg_photos = int(sum(c.get("photo_count", 0) for c in competitors_profiles) / max(len(competitors_profiles), 1))

    # Determine missing fields
    critical_fields = {"hours", "description", "menu_link", "address", "phone"}
    missing_fields = critical_fields - set(user_fields)

    # Compose a mock "AI" response
    summary = (
        f"Your business has {user_reviews} reviews (avg rating: {user_rating}). "
        f"Competitors average {avg_reviews} reviews (avg rating: {avg_rating}).\n"
        f"You have {user_photos} photos; competitors average {avg_photos}."
    )

    suggestions = []
    if user_photos < avg_photos:
        suggestions.append(f"Add more photos. Competitors average {avg_photos}, you have {user_photos}.")
    if user_reviews < avg_reviews:
        suggestions.append(f"Encourage more reviews. Competitors average {avg_reviews}, you have {user_reviews}.")
    if missing_fields:
        suggestions.append(f"You're missing these important fields: {', '.join(missing_fields)}.")
    if user_rating < avg_rating:
        suggestions.append("Consider ways to improve your average rating, such as responding to reviews or improving service.")

    # Mock: If no suggestions, say you're doing great!
    if not suggestions:
        suggestions.append("Your profile is as complete or better than your competitors. Great job!")

    return {
        "summary": summary,
        "suggestions": suggestions
    }

def build_query_for_prompt(query: str, cards: list) -> str:
    """
    Build a query string for the prompt based on the provided query and cards.
    If query is empty, use the first card's title and address."""
    query += "\n"
    for idx, c in enumerate(cards, 1):
        c_title = c.get("title", "Unknown Title")
        c_address = c.get("address", "Unknown Address")
        query += f"  {idx}. Title: {c_title}\n     Address: {c_address}\n"
    return query


def extract_json_from_response(content):
    """
    Extract JSON from a string, handling markdown code blocks if present.
    """
    # Try to extract JSON from markdown code block if present
    match = re.search(r'```(?:json)?\s*([\s\S]+?)\s*```', content)
    if match:
        json_str = match.group(1)
    else:
        json_str = content

    # Strip whitespace and try to parse
    json_str = json_str.strip()
    # print("Parsing this JSON string:", repr(json_str))
    return json.loads(json_str)


class AnalysisOutput(BaseModel):
    user_profile_cid: str
    competitor_profiles: list[str]
    comparison: list[str]
    suggestions: list[str]
    extra_insights: list[str]

@timeit("OpenAI API call")
def sendToAI(user_query: str, competitor_query: str) -> AnalysisOutput | None:
    ai_api_key = os.environ.get("OPENAI_API_KEY")

    if not ai_api_key:
        raise Exception("OPENAI_API_KEY environment variable is not set.")

    client = openai.OpenAI(api_key=ai_api_key)

    response = client.responses.parse(
        model="gpt-4o-mini",
        input=[
            {"role": "system", "content": restuaruant_compare_prompt_system()},
            {"role": "user", "content": restaurant_compare_prompt_user(user_query, competitor_query)}
        ],
        text_format=AnalysisOutput,
        #max_tokens=5000,
        temperature=0
    )

    content = response.output_parsed

    return content
